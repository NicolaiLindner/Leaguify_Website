{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "#BNN\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchbnn as bnn"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9cbce72fe190f372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv('../.env.local')  # Adjust the relative path according to your directory structure\n",
    "\n",
    "# Get the project path from environment variables\n",
    "project_path = os.getenv('MY_PROJECT_PATH')\n",
    "\n",
    "# Read CSV into DataFrame\n",
    "df = pd.read_csv(project_path)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:27:40.736874900Z"
    }
   },
   "id": "7a6a75a3ad49611f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:27:43.867224200Z"
    }
   },
   "id": "d8ef9ae87ecedd2"
  },
  {
   "cell_type": "raw",
   "source": [
    "# Test for u.gg champion info scraper per summoner"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1184147ef0e11f2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "url = \"https://u.gg/lol/profile/euw1/thehighground/champion-stats\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.binary_location = \"C:\\\\Users\\\\nicol\\\\Downloads\\\\chrome-win64\\\\chrome-win64\\\\chrome.exe\"  # Path to your Chrome executable\n",
    "\n",
    "service = Service(\"C:\\\\Users\\\\nicol\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.rt-tr-group\")))\n",
    "\n",
    "data = []  # List to store each row of data\n",
    "\n",
    "while True:\n",
    "    # Scroll to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Scroll back to the top of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Check if all rows have been loaded\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"div.rt-tr-group\")\n",
    "    if not rows or len(data) == len(rows):  # Adjusted condition to check data length instead of champions length\n",
    "        break\n",
    "    \n",
    "    # Otherwise, continue to extract the data\n",
    "    for i in range(len(data), len(rows)):\n",
    "        row = rows[i]\n",
    "        try:\n",
    "            name = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(2)\").text.strip()\n",
    "            rank = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(1)\").text.strip()\n",
    "            champion = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(3)\").get_attribute(\"textContent\")\n",
    "            winrate_stats = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(4)\").text.strip()\n",
    "            win_rate = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(5)\").text.strip()\n",
    "            pick_rate = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(7)\").text.strip()\n",
    "            ban_rate = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(6)\").text.strip()\n",
    "            matches = row.find_element(By.CSS_SELECTOR, \"div.rt-td:nth-of-type(8)\").text.strip()\n",
    "    \n",
    "            # Append the extracted data to the data list\n",
    "            data.append([rank, name, champion, winrate_stats, win_rate, pick_rate,ban_rate, matches])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error in row {i}: {e}\")\n",
    "\n",
    "\n",
    "# Convert the data list into a pandas DataFrame\n",
    "columns = ['Rank', 'Name', 'WinRate', 'KDA', 'Win rate', 'Pick Rate', 'Ban Rate', 'CS']\n",
    "df_scraped = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df_scraped.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:27:43.886659800Z"
    }
   },
   "id": "b3152e5b29ea1a0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "url = \"https://u.gg/lol/profile/euw1/thehighground/champion-stats\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.binary_location = \"C:\\\\Users\\\\nicol\\\\Downloads\\\\chrome-win64\\\\chrome-win64\\\\chrome.exe\"\n",
    "\n",
    "service = Service(\"C:\\\\Users\\\\nicol\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.rt-tr-group\")))\n",
    "\n",
    "# ... (your existing imports and setup code)\n",
    "\n",
    "# Initialize list to store each row of data\n",
    "data = []\n",
    "\n",
    "# Get all the rows\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"div.rt-tr-group\")\n",
    "\n",
    "for i in range(1, len(rows) + 1):  # start from 1 because CSS nth-child starts from 1\n",
    "    try:\n",
    "        # Create CSS selectors based on the row number for each column\n",
    "        selectors = {\n",
    "            'Champion': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > span:nth-child(2)\",\n",
    "            'WinRate': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(3) > div:nth-child(1) > span:nth-child(3)\",\n",
    "            'StrongRate': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(3) > div:nth-child(1) > strong:nth-child(1)\",\n",
    "            'KDA': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(4) > div:nth-child(1) > div:nth-child(1) > strong:nth-child(1)\",\n",
    "            'LP': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(5) > span:nth-child(1)\",\n",
    "            'MaxKills': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(6) > span:nth-child(1)\",\n",
    "            'MaxDeaths': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(7)\",\n",
    "            'CS': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(8) > span:nth-child(1)\",\n",
    "            'Damage': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(9) > span:nth-child(1)\",\n",
    "            'Gold': f\"div.rt-tr-group:nth-child({i}) > div:nth-child(1) > div:nth-child(10) > span:nth-child(1)\"\n",
    "        }\n",
    "        \n",
    "        # Find the elements and extract the text\n",
    "        row_data = []\n",
    "        for key, selector in selectors.items():\n",
    "            element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "            text = element.text.strip() if element.text else 'N/A'\n",
    "            row_data.append(text)\n",
    "        \n",
    "        # Append to data list\n",
    "        data.append(row_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in row {i}: {e}\")\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "columns = ['Champion', 'WinsLoses', 'Winrate', 'KDA', 'LP', 'MaxKills', 'MaxDeaths', 'CS', 'Damage', 'Gold']\n",
    "df_individual = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Display the DataFrame (you could also save it to a file)\n",
    "df_individual.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:27:56.633609100Z"
    }
   },
   "id": "23831ee41d959dcc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:28:04.787137100Z"
    }
   },
   "id": "6bc7e3ced2edcb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:28:04.789563200Z"
    }
   },
   "id": "73260f07da312cb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Select features and target\n",
    "feature_columns = ['Tier', 'Win rate', 'Pick Rate', 'Ban Rate', 'Matches', 'gameDuration', 'championId', 'summonerLevel', 'teamId']\n",
    "target_column = 'win'\n",
    "\n",
    "# Handle categorical variables and fill NaNs\n",
    "df[feature_columns] = df[feature_columns].apply(lambda x: x.astype('category').cat.codes if x.dtype == 'object' else x)\n",
    "df[feature_columns] = df[feature_columns].fillna(df[feature_columns].mean())\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = df[feature_columns].values\n",
    "Y = df[target_column].values\n",
    "\n",
    "# Scale the features\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x, y = torch.from_numpy(X_scaled).float(), torch.from_numpy(Y).long()\n",
    "\n",
    "# Step 2: Define Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=len(feature_columns), out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=100, out_features=2)\n",
    ")\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 3: Train Model\n",
    "for step in range(10000):\n",
    "    pre = model(x)\n",
    "    ce = ce_loss(pre, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    ce.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "_, predicted = torch.max(pre.data, 1)\n",
    "total = y.size(0)\n",
    "correct = (predicted == y).sum()\n",
    "print('- Accuracy: %f %%' % (100 * float(correct) / total))\n",
    "print('- CE : %2.2f' % (ce.item()))\n",
    "\n",
    "# Step 4: Test Model\n",
    "# ... (You can use your own visualization method similar to draw_plot function)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-23T11:28:04.793070500Z"
    }
   },
   "id": "50b02cc0564c311f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(y.numpy(), predicted.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "714a997ec00f6ef9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=len(feature_columns), out_features=100),\n",
    "    nn.ReLU(),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=100, out_features=2),\n",
    ")\n",
    "\n",
    "# Loss and Optimizer\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train Model\n",
    "for step in range(3000):\n",
    "    pre = model(x)\n",
    "    ce = ce_loss(pre, y)\n",
    "    kl = kl_loss(model)\n",
    "    cost = ce + 0.1 * kl\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "_, predicted = torch.max(pre.data, 1)\n",
    "total = y.size(0)\n",
    "correct = (predicted == y).sum()\n",
    "print('- Accuracy: %f %%' % (100 * float(correct) / total))\n",
    "print('- CE : %2.2f, KL : %2.2f' % (ce.item(), kl.item()))\n",
    "\n",
    "# Confusion Matrix Function\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Visualization\n",
    "plot_confusion_matrix(y.numpy(), predicted.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5d881c13159e490d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# URL\n",
    "url = \"https://u.gg/lol/profile/euw1/thehighground/champion-stats\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.binary_location = \"C:\\\\Users\\\\nicol\\\\Downloads\\\\chrome-win64\\\\chrome-win64\\\\chrome.exe\"\n",
    "\n",
    "service = Service(\"C:\\\\Users\\\\nicol\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.rt-tr-group\")))\n",
    "\n",
    "# Initialize list to store each row of data\n",
    "data = []\n",
    "\n",
    "# Get page source and create BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Get all the rows using BeautifulSoup\n",
    "rows = soup.select(\"div.rt-tr-group\")\n",
    "\n",
    "for i, row in enumerate(rows, 1):  # start from 1 because CSS nth-child starts from 1\n",
    "    try:\n",
    "        selectors = {\n",
    "            'Champion': \"div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > span:nth-child(2)\",\n",
    "            'WinsLoses': \"div:nth-child(1) > div:nth-child(3) > div:nth-child(1) > span:nth-child(3)\",\n",
    "            'Winrate': \"div:nth-child(1) > div:nth-child(3) > div:nth-child(1) > strong:nth-child(1)\",\n",
    "            'KDA': \"div:nth-child(1) > div:nth-child(4) > div:nth-child(1) > div:nth-child(1) > strong:nth-child(1)\",\n",
    "            'KillsDeathsAssists': \"div:nth-child(1) > div:nth-child(4) > div:nth-child(1) > span:nth-child(2)\",  # New field\n",
    "            'LP': \"div:nth-child(1) > div:nth-child(5) > span:nth-child(1)\",\n",
    "            'MaxKills': \"div:nth-child(1) > div:nth-child(6) > span:nth-child(1)\",\n",
    "            'MaxDeaths': \"div:nth-child(1) > div:nth-child(7)\",\n",
    "            'CS': \"div:nth-child(1) > div:nth-child(8) > span:nth-child(1)\",\n",
    "            'Damage': \"div:nth-child(1) > div:nth-child(9) > span:nth-child(1)\",\n",
    "            'Gold': \"div:nth-child(1) > div:nth-child(10) > span:nth-child(1)\"\n",
    "        }\n",
    "        \n",
    "        row_data = []\n",
    "        for key, selector in selectors.items():\n",
    "            element = row.select_one(selector)\n",
    "            text = element.get_text(strip=True) if element else 'N/A'\n",
    "            row_data.append(text)\n",
    "        \n",
    "        data.append(row_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in row {i}: {e}\")\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "columns = ['Champion', 'WinsLoses', 'Winrate', 'KDA', 'KillsDeathsAssists', 'LP', 'MaxKills', 'MaxDeaths', 'CS', 'Damage', 'Gold']\n",
    "df_individual = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_individual.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6e7fc8a0e365da8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# URL\n",
    "url = \"https://u.gg/lol/profile/euw1/leaguify/champion-stats?queueType=normal_draft_5x5\"\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.binary_location = \"C:\\\\Users\\\\nicol\\\\Downloads\\\\chrome-win64\\\\chrome-win64\\\\chrome.exe\"\n",
    "\n",
    "service = Service(\"C:\\\\Users\\\\nicol\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.rt-tr-group\")))\n",
    "\n",
    "# Initialize list to store each row of data\n",
    "data = []\n",
    "\n",
    "# Get page source and create BeautifulSoup object\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Get all the rows using BeautifulSoup\n",
    "rows = soup.select(\"div.rt-tr-group\")\n",
    "\n",
    "for i, row in enumerate(rows, 1):  # start from 1 because CSS nth-child starts from 1\n",
    "    try:\n",
    "        selectors = {\n",
    "            'Champion': \"div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > span:nth-child(2)\",\n",
    "            'WinsLoses': \"div:nth-child(1) > div:nth-child(3) > div:nth-child(1) > span:nth-child(3)\",\n",
    "            'Winrate': \"div:nth-child(1) > div:nth-child(3) > div:nth-child(1) > strong:nth-child(1)\",\n",
    "            'KDA': \"div:nth-child(1) > div:nth-child(4) > div:nth-child(1) > div:nth-child(1) > strong:nth-child(1)\",\n",
    "            'KillsDeathsAssists': \"div:nth-child(1) > div:nth-child(4) > div:nth-child(1) > span:nth-child(2)\",\n",
    "            'LP': \"div:nth-child(1) > div:nth-child(5) > span:nth-child(1)\",\n",
    "            'MaxKills': \"div:nth-child(1) > div:nth-child(6) > span:nth-child(1)\",\n",
    "            'MaxDeaths': \"div:nth-child(1) > div:nth-child(7)\",\n",
    "            'CS': \"div:nth-child(1) > div:nth-child(8) > span:nth-child(1)\",\n",
    "            'Damage': \"div:nth-child(1) > div:nth-child(9) > span:nth-child(1)\",\n",
    "            'Gold': \"div:nth-child(1) > div:nth-child(10) > span:nth-child(1)\"\n",
    "        }\n",
    "        \n",
    "        row_data = []\n",
    "        for key, selector in selectors.items():\n",
    "            element = row.select_one(selector)\n",
    "            text = element.get_text(strip=True) if element else 'N/A'\n",
    "            row_data.append(text)\n",
    "        \n",
    "        data.append(row_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in row {i}: {e}\")\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "columns = ['Champion', 'WinsLoses', 'Winrate', 'KDA', 'KillsDeathsAssists', 'LP', 'MaxKills', 'MaxDeaths', 'CS', 'Damage', 'Gold']\n",
    "df_individual = pd.DataFrame(data, columns=columns)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "397fc8ddb8389724"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_individual.head(200)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "34be29fd361efd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a26d50552b5f89e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "667c7868637826ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9d907d2deb73430e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
